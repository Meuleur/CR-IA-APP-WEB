import os
import httpx
from fastapi import HTTPException

PROVIDER = os.getenv("LLM_PROVIDER", "ollama")
HOST = os.getenv("OLLAMA_HOST", "http://127.0.0.1:11434")

# Par d√©faut, on prend le tag que tu as d√©j√† tir√©.
MODEL = os.getenv("LLM_MODEL", "gemma2:latest")

# üîß R√©glages pour maximiser la fid√©lit√© et limiter les hallucinations
LLM_OPTIONS = {
    "temperature": 0.2,       # sorties plus factuelles
    "top_p": 0.9,
    "repeat_penalty": 1.1,
    "num_ctx": 8192,          # plus de contexte visible par le mod√®le
    # "num_predict": 1024,    # optionnel: plafonne la longueur de sortie
}

SYSTEM = (
    "Tu es un r√©dacteur de comptes rendus techniques en fran√ßais. "
    "Objectif: EXHAUSTIVIT√â, Z√âRO PERTE D'INFO, AUCUNE INVENTION.\n"
    "- Conserve TOUTES les informations op√©rationnelles: horaires, lieux, √©quipements, "
    "mesures, seuils/consignes, anomalies, d√©cisions, actions, personnes/√©quipes, suivis.\n"
    "- Conserve les UNIT√âS, les VALEURS CHIFFR√âES, les NOMS d‚Äô√©quipements (ex: P_RRI_03), "
    "et les observations exactes (ex: bruits, doses, temp√©ratures).\n"
    "- Si une rubrique n‚Äôa pas d‚Äôinformation dans le verbatim, LAISSE-LA VIDE (n‚Äôinvente pas).\n"
    "- Formate la sortie STRICTEMENT en Markdown, sections ci‚Äëdessous, sans autre texte.\n"
)

TEMPLATE = """Reformate le texte suivant SANS R√âSUMER NI OMETTRE d‚Äôinformations techniques.
Tu dois r√©√©crire les phrases pour les rendre claires, mais sans perdre de d√©tails.
Respecte EXACTEMENT ce gabarit Markdown (utilise des puces concises et actionnables) :

# Compte rendu
## Contexte
- ...

## Points cl√©s (bullet points)
- ...

## D√©cisions
- ...

## Actions (qui / quoi / deadline)
- [ ] Responsable: ..., Action: ..., Deadline: JJ/MM/AAAA (ou horizon relatif si aucune date fournie)

## Risques / Points ouverts
- ...

## Prochaines √©tapes
- ...

Contraintes de sortie :
- Garde toutes les donn√©es (heures, valeurs, appareils, lieux, unit√©s).
- N‚Äôinvente rien : si l‚Äôinfo n‚Äôexiste pas, laisse la puce vide ou n‚Äôajoute pas de ligne inutile.
- √âvite les phrases vagues : chaque puce doit contenir un FAIT pr√©cis ou une ACTION.

Texte source (verbatim) :
\"\"\"{transcript}\"\"\""""

async def generate_report_from_transcript(transcript: str) -> str:
    if PROVIDER != "ollama":
        raise HTTPException(500, detail="LLM_PROVIDER non support√©")

    messages = [
        {"role": "system", "content": SYSTEM},
        {"role": "user", "content": TEMPLATE.format(transcript=transcript)},
    ]

    payload = {
        "model": MODEL,
        "messages": messages,
        "stream": False,
        "options": LLM_OPTIONS,
    }

    try:
        async with httpx.AsyncClient(timeout=120) as client:
            r = await client.post(f"{HOST}/api/chat", json=payload)
            r.raise_for_status()
            data = r.json()
            return (data.get("message", {}).get("content") or "").strip()
    except httpx.ConnectError as e:
        raise HTTPException(503, detail=f"Ollama injoignable sur {HOST}. Lance 'ollama serve'. ({e})")
    except httpx.HTTPStatusError as e:
        raise HTTPException(502, detail=f"Ollama a r√©pondu {e.response.status_code}: {e.response.text[:300]}")
    except Exception as e:
        raise HTTPException(500, detail=f"Erreur LLM: {e}")